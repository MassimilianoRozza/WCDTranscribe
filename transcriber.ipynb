{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description\n",
        "\n",
        "This Python script for Google Colab automates the batch transcription of Italian audio files using OpenAI's Whisper model. Audio files are processed directly from Google Drive, and the resulting transcriptions are saved as text files in the same folder.\n",
        "\n",
        "## Variable Description\n",
        "\n",
        "- `model_name`: Specifies the Whisper model to use (\"tiny\", \"base\", \"small\", \"medium\", \"large\"). Larger models offer greater accuracy but require more time and resources.\n",
        "- `lang`: Sets the audio file language to \"it\" (Italian).\n",
        "- `in_folder`: Path on Google Drive where the audio files to be transcribed are located.\n",
        "- `out_folder`: Path on Google Drive where the transcriptions will be saved.\n",
        "\n",
        "## Audio File Structure\n",
        "\n",
        "Audio files must be organized in the `in_folder` folder using the following naming convention:\n",
        "\n",
        "`<lesson_identifier>.<recording_number>.<extension>`\n",
        "\n",
        "Where `<lesson_identifier>` can be a number or a date (or any string without dots \".\").\n",
        "\n",
        "### Examples:\n",
        "\n",
        "- `1.1.m4a` (first recording of lesson 1)\n",
        "- `2023-10-27.1.mp3` (first recording of the lesson from October 27, 2023)\n",
        "- `AdvancedCourse.2.wav` (second recording of the AdvancedCourse lesson)\n",
        "\n",
        "## Transcription Structure\n",
        "\n",
        "Transcriptions are saved in the `out_folder` folder using the following naming convention:\n",
        "\n",
        "`<lesson_identifier>.txt`\n",
        "\n",
        "### Examples:\n",
        "\n",
        "- `1.txt` (contains the transcription of 1.1.m4a)\n",
        "- `2023-10-27.txt` (contains the transcription of 2023-10-27.1.mp3)\n",
        "- `AdvancedCourse.txt` (contains the transcription of AdvancedCourse.2.wav)"
      ],
      "metadata": {
        "id": "G9FBRmxSVVRa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lOT5Txbpiuq_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U openai-whisper;\n",
        "!sudo apt install ffmpeg;\n",
        "import whisper\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "model_name = \"large\" #whisper model name\n",
        "lang = \"it\" # audio language\n",
        "in_folder = \"drive/MyDrive/audio-files/\" #audio files folder\n",
        "out_folder = \"drive/MyDrive/audio-files/\" #transcriptions folder"
      ],
      "metadata": {
        "collapsed": true,
        "id": "h0iUXtKri6WD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "done = [] #files already transcripted\n",
        "model = whisper.load_model(model_name)"
      ],
      "metadata": {
        "id": "ti5B4RitW9DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(out_folder, exist_ok=True)  # Crea la cartella se non esiste\n",
        "transcriptions = os.listdir(out_folder)\n",
        "for file in transcriptions:\n",
        "    if file.endswith(\".txt\"):\n",
        "      done.append(file.split(\".\")[0])\n",
        "print(done)"
      ],
      "metadata": {
        "id": "dMXJ00HBNZPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audios = os.listdir(in_folder)\n",
        "audios.sort()",
        "for file in audios:\n",
        "  print(\"ELABORATION: \" + file)\n",
        "  if file.split(\".\")[0] in done:\n",
        "    print(\"SKIP: \" + file)\n",
        "    continue\n",
        "  else:\n",
        "    print(\"TRANSCRIBING: \" + file)\n",
        "    try:\n",
        "      result = model.transcribe(in_folder + file, language=lang)\n",
        "    except whisper.WhisperError as e:\n",
        "      print(f\"ERROR while working on {file}: {e} \")\n",
        "    print(\"SAVING: \" + file + \" transcription\")\n",
        "    with open(out_folder + file.split(\".\")[0] + \".txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "      f.write(result[\"text\"])\n",
        "    print(\"DONE: \" + file)\n",
        "    print(\"=======================================\")\n",
        "\n",
        "print(\"======== END ========\")"
      ],
      "metadata": {
        "id": "D_ifNlGeOiYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
